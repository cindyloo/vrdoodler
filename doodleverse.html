 <!DOCTYPE html>
<head>
    <meta charset="utf-8">
    <title>VRDoodler!!!-beta</title>
 <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
</head>
		
    <script type="text/javascript" src="http://code.jquery.com/jquery-latest.pack.js"></script>
    <script src="//code.jquery.com/ui/1.11.4/jquery-ui.js"></script>
	<script>
		// Opera 8.0+ (UA detection to detect Blink/v8-powered Opera)
		isOpera = !!window.opera || navigator.userAgent.indexOf(' OPR/') >= 0;
		// Firefox 1.0+
		isFirefox = typeof InstallTrigger !== 'undefined';
		// At least Safari 3+: "[object HTMLElementConstructor]"
		isSafari = Object.prototype.toString.call(window.HTMLElement).indexOf('Constructor') > 0;
		// At least IE6
		isIE = /*@cc_on!@*/false || !!document.documentMode;
		// Edge 20+
		isEdge = !isIE && !!window.StyleMedia;
		// Chrome 1+
		isChrome = !!window.chrome && !!window.chrome.webstore;
		// Blink engine detection
		isBlink = (isChrome || isOpera) && !!window.CSS;
		
		if(isChrome || isFirefox){
		   // is Google Chrome on IOS
		} else { 
		  alert("VRDoodler requires Chrome or FF");
		 } 
		 
		 
		 
		 function isMobBrowser() { 
			 if( navigator.userAgent.match(/Android/i)
			 || navigator.userAgent.match(/webOS/i)
			 || navigator.userAgent.match(/iPhone/i)
			 || navigator.userAgent.match(/iPad/i)
			 || navigator.userAgent.match(/iPod/i)
			 || navigator.userAgent.match(/BlackBerry/i)
			 || navigator.userAgent.match(/Windows Phone/i)
			 ){
				return true;
			  }
			 else {
				return false;
			  }
		}
		 
		var getParams = (function() {
	
			var _get = {};
			var re = /[?&]([^=&]+)(=?)([^&]*)/g;
			while (m = re.exec(location.search))
				_get[decodeURIComponent(m[1])] = (m[2] == '=' ? decodeURIComponent(m[3]) : true);
			return _get;
		})();
		
		
		function inMobileMode(){
		
			if (isMobBrowser() || getParams["mobile"] == 1)
				return true;
			else
				return false;
		
		}
	 
	</script>

   <script src="js/three.js"></script>

	<!--
	  VRControls.js acquires positional information from connected VR devices and applies the transformations to a three.js camera object.
	   -->
	<script src="node_modules/webvr-boilerplate/node_modules/three/examples/js/controls/VRControls.js"></script>

	<!--
	  VREffect.js handles stereo camera setup and rendering.
	  -->
	<script src="node_modules/webvr-boilerplate/node_modules/three/examples/js/effects/VREffect.js"></script>

	<!--
	  A polyfill for WebVR using the Device{Motion,Orientation}Event API.
	  -->
	<script src="js/webvr-polyfill.js"></script>

	<!--
	  Helps enter and exit VR mode, provides best practices while in VR.
	  -->
	<script src="js/webvr-manager.js"></script>

	<script src="js/loaders/OBJLoader.js"></script>
 
	
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	
	  ga('create', 'UA-75274623-1', 'auto');
	  ga('send', 'pageview');
	
	</script>

<script>
try {
    window.AudioContext = window.AudioContext || window.webkitAudioContext;
    window.audioContext = new window.AudioContext();
} catch (e) {
    console.log("No Web Audio API support");
}

/*
 * WebAudioAPISoundManager Constructor
 */
 var WebAudioAPISoundManager = function (context) {
    this.context = context;
    this.bufferList = {};
    this.playingSounds = {};
};

/*
 * WebAudioAPISoundManager Prototype
 */
WebAudioAPISoundManager.prototype = {
     addSound: function (url, startPlayingIfLoaded) {
        // Load buffer asynchronously
        var request = new XMLHttpRequest();
        request.open("GET", url, true);
        request.responseType = "arraybuffer";

        var self = this;

        request.onload = function () {
            // Asynchronously decode the audio file data in request.response
            self.context.decodeAudioData(
                request.response,

                function (buffer) {
                    if (!buffer) {
                        alert('error decoding file data: ' + url);
                        return;
                    }
                    self.bufferList[url] = buffer;
                    startPlayingIfLoaded();
  
                });
        };

        request.onerror = function () {
            alert('BufferLoader: XHR error');
        };

        request.send();
    },
    stopSoundWithUrl: function(url) {
        if(this.playingSounds.hasOwnProperty(url)){
            for(var i in this.playingSounds[url]){
                if(this.playingSounds[url].hasOwnProperty(i))
                    this.playingSounds[url][i].noteOff(0);
            }
        }
    }
};

/*
 * WebAudioAPISound Constructor
 */
 var WebAudioAPISound = function (url, options, afterLoad) {
    this.settings = {
        loop: false
    };

    for(var i in options){
        if(options.hasOwnProperty(i))
            this.settings[i] = options[i];
    }

    this.url = url ;
    window.webAudioAPISoundManager = window.webAudioAPISoundManager || new WebAudioAPISoundManager(window.audioContext);
    this.manager = window.webAudioAPISoundManager;
    this.manager.addSound(this.url, afterLoad);
    
};

/*
 * WebAudioAPISound Prototype
 */
WebAudioAPISound.prototype = {
    play: function () {
        var buffer = this.manager.bufferList[this.url];
        //Only play if it's loaded yet
        if (typeof buffer !== "undefined") {
            var source = this.makeSource(buffer);
            source.loop = this.settings.loop;
            source.start(0);

            if(!this.manager.playingSounds.hasOwnProperty(this.url))
                this.manager.playingSounds[this.url] = [];
            this.manager.playingSounds[this.url].push(source);
        }
    },
    stop: function () {
        this.manager.stopSoundWithUrl(this.url);
    },
    getVolume: function () {
        return this.translateVolume(this.volume, true);
    },
    //Expect to receive in range 0-100
    setVolume: function (volume) {
        this.volume = this.translateVolume(volume);
    },
    translateVolume: function(volume, inverse){
        return inverse ? volume * 100 : volume / 100;
    },
    makeSource: function (buffer) {
        var source = this.manager.context.createBufferSource();
        var gainNode = this.manager.context.createGain();
        gainNode.gain.value = this.volume ? this.volume: 0.5;
        source.buffer = buffer;
        source.connect(gainNode);
        gainNode.connect(this.manager.context.destination);
        return source;
    }
};

</script>

  <body>  
  
  <div class="">
		<h1><a href="index.html"><img class="logo" src="assets/images/vrdoodler_icon.png"></a></h1>
		<input id="playback" type="button" data-toggle="tooltip" value="" title="Playback"><i class="glyphicon glyphicon glyphicon-sunglasses"></i></input>
	
	</div>
	<audio id="danny" src="assets/danny.wav"></audio>
</body>



<script>
 
 
 	var camera, scene, expScene, renderer,orbitcamera,light;
    var geometry, material, mesh;
    var controls, minicamera;
    var effects, vrmanager;
    var defaultControls, orientControls, transformControls;
    var transGeo, transMat;
 	var context = null;
	var currentPlane = 0;
	var drawnline = [];
	var container, canvas;


	var MAX_POINTS = 2000;
	var PB_LINE_VERTEX_COUNT_MAX= 0; //change this once we get our first line...
	var countVertices = 0;
	var sketchContainer,objContainer ;
	var CURRENTspline = -1; //incremented at initNewLine
var grid ;
	var mouse = new THREE.Vector2();
	var mouseXOFFSET = 1.01;
	var mouseYOFFSET = .975;
	var currentIntersected, currentIntersectedPoint, lastIntersected, lastIntersectedPoint;
	var lastLineIntersection = null;
	
	
	var ORBITMODE = 0;  //when not drawing
	var FREEHANDMODE = 1;  //when drawing
	var SNAPMODE = 0;		//snap to pre-existing line/objects	
	var DRAWMODE = 0;//ORBITMODE;
	var MOVEMODE=0;
	var CURRENTLINEWIDTH = 2;
	var PLANEROTATIONCOLOR = 0xff000;
	var PLANELOCK = 0;  //lock currentIntersection
	var STEREOSCOPIC = 0;
	
	var SNAPPLANETOGRID = 0;
	
	var cameraAngle = 0;
	var pivotRadius = 1;
	var pivotPoint;
	var initCamRotPos =0;
	var squareAngle = 90 * Math.PI/180;
	var plane, planegeo, planemat,planeBoundsMat, planeBounds;
	var PLANEROTATE = 0;
	var COLOR = 0;
	var linematerial = null;
	var dollyAngle = 700;

	var edges, cameraHelp;
	
	var start = Date.now();
	var clock = new THREE.Clock();
	var PLAYBACK = 0;
	var playBackCount = 0;
	var PLAYBACKSPEED = .0005;
	
	//audio stuff
	var audioCtx ; // define audio context
	var sound1 = {};  //sound object
	// Webkit/blink browsers need prefix, Safari won't work without window.
	var bufferLoader;
	var analyser ,distortion,mainVolume ,biquadFilter, panner ;


	

	function init(){	
		container = document.createElement( 'div' );
		container.style.position = 'absolute';
		container.style.top = '0';
		container.style.width = '100%';
		container.style.textAlign = 'center';
		container.style.color = '#000';
		container.style.fontWeight = 'bold';
		container.style.backgroundColor = '#000';
		container.style.zIndex = '1';
		container.style.fontFamily = 'Monospace';
		document.body.appendChild( container );

		sound1 = new WebAudioAPISound("assets/danny.wav", null, 
			function(){
				sound1.play();
			});
		renderer = new THREE.WebGLRenderer({antialias: true});
		renderer.setPixelRatio(window.devicePixelRatio);
		// Append the canvas element created by the renderer to document body element.
		container.appendChild( renderer.domElement );
		// Create a three.js scene.
		scene = new THREE.Scene();
		// Create a three.js camera.
		camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 10000);
		camera.position.set(0,.5,5);
		// Apply VR headset positional data to camera.
		orientControls = new THREE.VRControls(camera);
		// Apply VR stereo rendering to renderer.
		var effect = new THREE.VREffect(renderer);
		effect.setSize(window.innerWidth, window.innerHeight);
			   		   
		objContainer = new THREE.Object3D();
		objContainer.name = "objContainer";
		objContainer.geometry = null;

  		scene.add(objContainer);
  		
  		//sketchContainer.add(camera);
		//sketchContainer.lookAt(0,5,0);
  		
  		
		//setupGrid();
	
	
	 	 var params = {
		  hideButton: false, // Default: false.
		  isUndistorted: false // Default: false.
		};
		vrmanager = new WebVRManager(renderer, effect, params);
  		    
   		vrmanager.button.vrButton.style.width = '25px';
   		vrmanager.button.vrButton.style.height ='25px';
  		
			
		
		window.addEventListener('resize', onWindowResize, false);
		document.getElementById("playback").onclick = togglePlayBackMode;


window.addEventListener('touchstart', function(){
	sound1.play();
	toggleSound();
	togglePlayBackMode();
	});


		
		$(document).ready(function(){

			if (inMobileMode())
				 toggleStereoscopic();
				 
		
				
	
 
	  });
	
	   

	}

	function toggleSound(){
		if (sound1.playbackState ===sound1.PLAYING_STATE )	
			sound1.stop();
		else
			sound1.start();
		
	}
	
	/*if URL params say load the doodleverse */
	function loadInitialImages(dir){
		    var xhrImg = new XMLHttpRequest();
 
       		xhrImg.onreadystatechange=function() {
				if (xhrImg.readyState==4 && xhrImg.status==200) {	
				
					if (xhrImg.responseText.indexOf("?PHP")> -1){  //in case we don't have php on the localhost
						
						
						dir = "assets/doodleverse/";
						var images = [dir + "armymen.txt"];// + dir +"house.jpg",dir +"sun.jpg" ];
						 handleImport(images);
					}
					else{
						var objects =  xhrImg.responseText.split('EOF');    
						
						objects.forEach(function(object){
							var cleanedobj = object.replace(/EOF/,'');
							obj = new THREE.OBJLoader().parse(cleanedobj);
						
			
							obj.name = "linedoodleverse";
							importScene(obj);
						});		
						//if (sound && sound1.buffer) //how bad is this to do?
						//	sound1.start(0); //start audio when images load	
						
				  		raycastGazeForDollyCam();
				  		                   
						
				  	}
				}else{
					if (xhrImg.responseText== ""){  //in case we don't have php on the localhost
							console.log("can't get file for loadInitialImages");			
						
					}
				}
			} 
			//var fatcowhostpath = "/home/users/web/b285/moo.vrdoodlercom/";
			if (location.hostname == "localhost") //debugging
				xhrImg.open("GET", "/getObjFiles");//easier to use node to get all the files in there even for debugging..);					
			else
				xhrImg.open("GET", "phpsessions/getObjFiles.php");//?q=" + fatcowhostpath + "assets/doodleverse");//"vrdoodler.html?loaddoodleverse=1");
	 
			xhrImg.send();  

    	}
	function loadImages(imgArray){
	
			loadedImages = imgArray;
			//create filelist or something to hand to handleImport
			
		}
	
	function handleImport() {
  			var fileList = this.files; /* now you can work with the file list */
  			
  			for (var i = 0; i < fileList.length; i++) {
  			
  				f = fileList[i];		 
				var reader  = new FileReader();
				var extension;
				if (f.name)
					extension = f.name.split( '.' ).pop().toLowerCase();
				else
					extension = f.split( '.' ).pop().toLowerCase();

				
				switch(extension){
					case 'json':
					case '3geo':
					case '3mat':
					case '3obj':
					case '3scn':
	
					reader.addEventListener( 'load', function ( event ) {
						
						var contents = event.target.result;
						try {
							data = JSON.parse( contents );
						} catch ( error ) {
							alert( error );
							return;
						}
						importJSONObject( f.name, data );
	
					}, false );
					reader.readAsText( f );	
					break;
	
				case 'obj':
				case 'txt':
	
					reader.addEventListener( 'load', function ( event ) {
						var contents = event.target.result;
						var object = new THREE.OBJLoader().parse( contents );
						object.name = f.name;
						importScene(object);					
					}, false );
					reader.readAsText( f );
						
					
					break;
					
				case 'jpg':
				case 'png':
					var photo;
					var preview = document.querySelector('#preview');
					
				 	reader.addEventListener("load", function () {
						var image= new Image();
						var image2 = new Image();
						image.height = 1000;
						image.title = f.name;
						image.src = this.result;
						image2.height = 100;
						image2.title = f.name;
						image2.src = this.result;
						preview.appendChild( image2);
						$("#preview").css("margin-bottom",120);
	
						var texture = new THREE.Texture( image );
						texture.name=f.name;
						texture.needsUpdate = true;
						var psphere = makePhotoSphere(texture,25, 100);
						
						$("a.imgclose").css("visibility","visible");
					});
			
				  	reader.readAsDataURL(f);
					break;
				}	
  			} //for
		}
	
	
	function importScene(object){  //if in a group, we want to preserve it... have to change initNewLine...
	
				object.traverse( function ( child ) {						
						if ( child instanceof THREE.Line ) { //THREE.Line
									//initNewLine(null, null, child.geometry, child.geometry.attributes.position);
									initNewLine(null, null, child);
						}
					 });
					 
					
		

	}

	
	/* right outta the three.js editor. thanks @mrdoob! */
	function importJSONObject(fn,data){
		var material;
				
	    var loader = new THREE.JSONLoader();
		var result = loader.parse( data );
		if ( result.materials !== undefined ) {

				if ( result.materials.length > 1 ) {
					material = new THREE.MultiMaterial( result.materials );
				} else {
					material = result.materials[ 0 ];
				}
		} else {
			material = new THREE.MeshStandardMaterial();
		}

		var geo = result.geometry;
		geo.sourceType = "ascii";
		geo.sourceFile = fn;

		var mesh;

		if ( geo.animation && geo.animation.hierarchy ) {
			mesh = new THREE.SkinnedMesh( geo, material );
		} else {
			mesh = new THREE.Mesh( geo, material );
		}
		
		var pos = new THREE.Vector3(0,0,0);	
		if (currentIntersected)
			pos = currentIntersected.position.copy();
		mesh.position.set(pos);
	
		mesh.userData.name = "fromjson";		
		objContainer.add( mesh );
	
	}



	var onProgress = function ( xhr ) {
					if ( xhr.lengthComputable ) {
						var percentComplete = xhr.loaded / xhr.total * 100;
						console.log( Math.round(percentComplete, 2) + '% downloaded' );
					}
				};

	var onError = function ( xhr ) {
	};
	


	
	
	function onWindowResize() {
		  effect.setSize(window.innerWidth, window.innerHeight);
		  camera.aspect = window.innerWidth / window.innerHeight;
		  camera.updateProjectionMatrix();
	}



	
	function toggleStereoscopic(){
		STEREOSCOPIC = STEREOSCOPIC?0:1;
	 	
	 	if (STEREOSCOPIC){
	 		orientControls.enabled=true;
	 		setOrientationControls();	 		
	 	}
		
	}
	
	
	function setupGrid(){
		if (!grid){grid = new THREE.GridHelper( 20, .5 );
			grid.name="grid";
			grid.setColors( 0x0000ff, 0x808080 );
			grid.position.y = 0;
			objContainer.add( grid );
		}
		grid.visible = true;
		
	}
	function toggleGrid(){
		if (userSettings.userLevel >0){
			if (grid){
				grid.visible = grid.visible?false:true;
				axisHelper.visible = axisHelper.visible?false:true;
			}else{
				setupGrid();
			}
		}
		$("#grid").prop("checked",grid.visible);
	}


      function setOrientationControls(e) {
        if (e && !e.alpha) {
          return;
        }
        orientControls.update();
      
        if (mostRecentDrawnLine() == null)
        	loadInitialImages();
        
        
        //window.removeEventListener('deviceorientation', setOrientationControls, true);
      }
      

    

	/* setup buffer geometry to store drawn vertices*/
	function initDrawnLine(lineImported,mv){
		
		var linename;
		var newOrImportedLine;
		if (!lineImported){  //freehand or snap, doesn't matter, init the line
			geometry = new THREE.BufferGeometry();
			positions = new Float32Array( MAX_POINTS * 3 ); // 3 vertices per point
			countVertices = 0;
			if (mv){
				positions[0] = mv.x;
				positions[1] = mv.y;
				positions[2] = mv.z;
				countVertices = 1;
			}
			geometry.addAttribute( 'position', new THREE.BufferAttribute( positions, 3 ) );	
			geometry.setDrawRange( 0, 1 );	
			linename = "line";
			
			linematerial = new THREE.LineBasicMaterial( { color: 0xffffff, linewidth: getCurrentLineWidth() } );
			newOrImportedLine = new THREE.Line( geometry,  linematerial );
			drawnline.push(newOrImportedLine); //to store line	
		mostRecentDrawnLine().position = mv; //for later...
		
		}else{ //loaded from OBJ file
			
			//lineImported.geometry.addAttribute( 'position', positions )
			//lineImported.setDrawRange( 0, geometry.attributes.position.count-1 );
			linename = "lineimported";
			newOrImportedLine = lineImported;//.clone();
			drawnline.push(newOrImportedLine); //to store line	
			//if (currentIntersected)
			//		mostRecentDrawnLine().position.copy(currentIntersectedPoint); //for later...
			//this doesn't work so well if the line is then copied and pasted...
		}
	
		
		
	    //linematerial = new THREE.ShaderMaterial(THREE.LineDisplacementShader); 
	    
		
		
		//mostRecentDrawnLine().position.copy(mv); //do I need this? hm no..
		mostRecentDrawnLine().name = linename;
		//mostRecentDrawnLine().geometry.attributes.position.slice(0, countVertices *3);
		mostRecentDrawnLine().geometry.attributes.position.needsUpdate = true; 
	
	
	console.log("init new Line");
	}
	

	function addToContainer(newline, group){
	
		//create new group or add to pre-existing 
		
		var lineGroup; 
		if (group != null){
			group.parent.name="linegroup";
			objContainer.add(group.parent);
		}else if (lastLineIntersection && lastLineIntersection.name == "line"){
			lastLineIntersection.parent.add(newline);
			lastLineIntersection = null;
		
		}else{
		
			lineGroup = new THREE.Object3D();
			lineGroup.add(newline);  
			lineGroup.name="linegroup";
			objContainer.add(lineGroup);
			
			
		}
	
	
	
	}
	
		
	//called from mouseDown
	//works for importing from file or if using mouse to start line
	function initNewLine(mouseVec, bUnproject, lineImported){

		
		if (!lineImported){
			 var vNow = new THREE.Vector3(mouseVec.x, mouseVec.y, mouseVec.z);
			 if (bUnproject)
				vNow.unproject(camera);
		
			initDrawnLine(null, vNow);

		}else //from import
		 	initDrawnLine(lineImported);
		
		addToContainer( mostRecentDrawnLine(), lineImported );
		
		
	
	}


	function mostRecentDrawnLine(){
		if (drawnline && drawnline.length > 0){
			CURRENTspline = drawnline.length -1;
			return drawnline[CURRENTspline];
		}
		return null;
	}

	function raycastGazeForDollyCam(){
		//TODO: should only run when in playback mode
		var vGaze = new THREE.Vector3(0,0,5);  //for now, let's make the gaze static

		camera.position.z = Math.cos(dollyAngle * Math.PI/360) *10 ;
		camera.position.x = Math.sin(dollyAngle * Math.PI/360) *10 ;
		dollyAngle += .15;
		if (dollyAngle >720) 
			dollyAngle = 0;
		//tell dolly to move along the path from camera origin at increments 
	
	}	
	function togglePlayBackMode(){
	
		PLAYBACK = PLAYBACK?0:1;
		if (PLAYBACK) {
			clock.start();
			clearLines();
			//dollyPath = makeDollyPlaybackPath();
			
			
		}else{
			clock.stop();
			for (var i=0;i< drawnline.length;i++){
				drawnline[i].geometry.setDrawRange( 0, drawnline[i].geometry.attributes.position.count-1);
			}
		}
		return PLAYBACK;
	
	}
	
	
	function clearLines(){
		var count = 0;
		for (var i=0;i< drawnline.length;i++){
				drawnline[i].geometry.setDrawRange( 0, 1);
		}
		return count;				
		
	}
	
	
	function aggregateVertexCount(){
		var count = 0;
		for (var i=0;i< drawnline.length;i++){
				count += drawnline[i].geometry.attributes.position.count;
		}
		return count;				
		
	}
	
		
	function pb_drawOneAtATime(){
		console.log("aggCount is " +  aggregateVertexCount());
		
		PB_LINE_VERTEX_COUNT_MAX =aggregateVertexCount(); 
		var verticesYetToBeDrawn = PB_LINE_VERTEX_COUNT_MAX - playBackCount;
		
		var linesLeftToDraw = playBackCount;
		for (var i=0;i< drawnline.length;i++){
			
			
			var howManyLinesToDraw = linesLeftToDraw;
			var thisLineDrawn = (howManyLinesToDraw > drawnline[i].geometry.attributes.position.count)? drawnline[i].geometry.attributes.position.count:howManyLinesToDraw;
			
			
			
			//count = verticesYetToBeDrawn > (drawnline[i].geometry.attributes.position.count/3)? drawnline[i].geometry.attributes.position.count/3:verticesYetToBeDrawn;
			for (var vertex=0;vertex< thisLineDrawn;vertex++){  //either the full lenght of the line or partial
				drawnline[i].geometry.setDrawRange( 0, vertex * 3);
				drawnline[i].geometry.attributes.position.needsUpdate = true; 
				
			}
			linesLeftToDraw -=  thisLineDrawn; //take this line off
			}
	}
	function pb_drawAllAtOnce(){
		for (var i=0;i< drawnline.length;i++){
				if (drawnline[i] === undefined){  //if any weirdness, clean it up
					drawnline.splice(i,1);
					continue;
				}
				if ((drawnline[i].geometry.attributes.position.count/3) > PB_LINE_VERTEX_COUNT_MAX) 
					PB_LINE_VERTEX_COUNT_MAX = (drawnline[i].geometry.attributes.position.count/3);
				var count = playBackCount;
				//determine what should be drawn
				//count from 0 to length vertices of line..
				//right now we are just going to animate each line at the same time....
				
				//truncate the count b/c playBackCount is the long pole
				if (playBackCount > drawnline[i].geometry.attributes.position.count)  //what?
					count =	drawnline[i].geometry.attributes.position.count;
				drawnline[i].geometry.setDrawRange( 0, (count) * 3);
				drawnline[i].geometry.attributes.position.needsUpdate = true; // required after the first render
			}
	
	}
	
	function drawBack(){
		//if (){
		//	pb_drawAllAtOnce();
		//} else {
		if (drawnline && drawnline.length > 0)
			pb_drawOneAtATime();
		//}
	
	}
	
	function runPlayBack(){
	
		if (PLAYBACK){
			drawBack();

			if (clock.getDelta() > PLAYBACKSPEED){
				playBackCount+= 100;
				//start = Date.now(); //not relevant
				
				
				console.log("playbackcount "+ playBackCount);
			}
			
			if (playBackCount > PB_LINE_VERTEX_COUNT_MAX){	
				playBackCount = 0;
				clearLines();
				if (sound1){
					sound1.stop(); 
					sound1.play(); 
				}		
			
			//document.getElementById("danny").stop();
			//document.getElementById("danny").play();
			}
		}	
		
		
		return PLAYBACK;
		
	}
	
	
	
	
	
	

	function animate(timestamp) {

		requestAnimationFrame(animate);

		
		camera.updateMatrixWorld();
		camera.updateProjectionMatrix();
		
		runPlayBack();
			
			//TODO add ability to draw while moving plane backwards or forwards
		
	
	
		render(timestamp);	 
		  
	
	
	   } 
	   
	function render(timestamp) {
		

		renderer.setClearColor( 0x000000);


		if (STEREOSCOPIC){
	 	
			 orientControls.update();
			 vrmanager.render(scene, camera, timestamp);
 			raycastGazeForDollyCam();
  

			//renderer.render( scene, camera );
  		}else{
  			
			renderer.render( scene, camera );
  		}
	}
		
	init();
	//cameraHelp = new THREE.CameraHelper(camera);
	//scene.add(cameraHelp);
	animate();
	
	
</script>
</html>
